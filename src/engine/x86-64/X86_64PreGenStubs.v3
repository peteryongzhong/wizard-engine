// Copyright 2023 Wizard Authors. All rights reserved.
// See LICENSE for details of Apache 2.0 license.

// Statically-allocated buffer for pre-generated code (in compiled binary).
def PAGE_SIZE = 4096u;
def PAGE_SIZE_i: int = 4096;
def PREGEN_CODE_MARKER = 0x7FAACCEE;
def pregen_header = Ref<X86_64PreGenHeader>.at(pregen_buffer, 0);
var pregen_header_size = X86_64PreGenHeader.size;
var global_stub_list: List<X86_64PreGenStub>;

// A layout used for storing global offsets into the generated code.
layout X86_64PreGenHeader { // XXX: compress
	+8	codeMarker:			i32;	// marker that indicates pregen code is present
	+12	fastDispatchTableOffset:	i32;	// dispatch table when probes disabled
	+16	probedDispatchTableOffset:	i32;	// dispatch table when probes enabled
	+20	codeStart:			i32;	// start of all executable code
	+24	intV3EntryOffset:		i32;	// entry into interpreter from V3 caller
	+28	intSpcEntryOffset:		i32;	// entry into interpreter from SPC caller
	+32	intIntEntryOffset:		i32;	// entry into interpreter from interpreter caller
	+36	deoptReentryOffset:		i32;	// re-enter interpreter from optimized code
	+40	oobMemoryHandlerOffset:		i32;	// handler for signals caused by OOB memory access
	+44	divZeroHandlerOffset:		i32;	// handler for signals caused by divide by zero
	+48	stackOverflowHandlerOffset:	i32;	// handler for signals caused by (value- or call-) stack overflow
	+56	hostCallStubOffset:		i32;	// host call stub that calls runtime
	+60	hostCallStubEnd:		i32;	// host call stub that calls runtime
	+64	codeEnd:			i32;	// end of all executable code
	=68;
}

layout X86_64PreGenStubOffsets {
	+0	start:	i32;
	+4	end:	i32;
	=8;
}

def allocPreGenHeaderOffsets() -> Ref<X86_64PreGenStubOffsets> {
	var offset = pregen_header_size;
	pregen_header_size += X86_64PreGenStubOffsets.size;
	return Ref<X86_64PreGenStubOffsets>.at(pregen_buffer, offset);
}

// Base class of pre-generated stubs.
class X86_64PreGenStub(
	name: string,
	userCode: RiUserCode,
	gen: (X86_64InterpreterCode, DataWriter) -> void) {

	private def offsets = allocPreGenHeaderOffsets();

	new() {
		global_stub_list = List.new(this, global_stub_list);
	}

	// Get the start of this stub.
	def getEntry() -> Pointer {
		X86_64PreGenStubs.gen();
		return CiRuntime.RESERVED_CODE_START + offsets.start;
	}
}

class X86_64PreGenFunc<P, R> extends X86_64PreGenStub {
	private var func: P -> R;

	new(name: string, userCode: RiUserCode, gen: (X86_64InterpreterCode, DataWriter) -> void) super(name, userCode, gen) { }

	// Get a function (with no closure type parameter) for the code pointer.
	def get() -> P -> R {
		if (func == null) func = CiRuntime.forgeClosure<void, P, R>(getEntry(), ());
		return func;
	}
	// Forge a closure using the entrypoint as the code pointer.
	def forgeClosure<C>(c: C) -> P -> R {
		return CiRuntime.forgeClosure<C, P, R>(getEntry(), c);
	}
}

// Simple stubs have no references in their frame and have a fixed size frame.
class X86_64SimpleStub extends RiUserCode {
	def stubName: string;
	def frameSize: int;

	new(stubName, frameSize: int) super(Pointer.NULL, Pointer.NULL) { }

	// Called from V3 runtime upon fatal errors to describe a frame for a stacktrace.
	def describeFrame(ip: Pointer, sp: Pointer, out: Range<byte> -> void) {
		if (Debug.stack) X86_64Stacks.traceIpAndSp(ip, sp, out);
		var msg = "\tin [";
		out(msg);
		out(stubName);
		msg = "-stub]\n";
		out(msg);
	}
	// Called from V3 runtime for a frame where {ip} is in the stub code.
	def nextFrame(ip: Pointer, sp: Pointer) -> (Pointer, Pointer) {
		sp += frameSize;	 // assume frame is allocated
		ip = sp.load<Pointer>(); // return address on stack
		return (ip + -1, sp + Pointer.SIZE); // XXX: V3 quirk with -1 (use RiOs?)
	}
}

// Interface to pre-generated code stubs.
def I: X86_64Interpreter;
component X86_64PreGenStubs {
	private def ic = X86_64InterpreterCode.new(Pointer.NULL, Pointer.NULL, pregen_header);
	private def hostCallStub = X86_64SimpleStub.new("host-call", 0);

	def getInterpreterCode() -> X86_64InterpreterCode {
		return (gen(), I.interpreterCode).last;
	}
	def getIntV3Entry() -> (WasmFunction, Pointer) -> Throwable {
		return (gen(), I.interpreterCode.intV3Entry).last;
	}
	def getSpcIntEntry() -> Pointer {
		gen();
		return I.interpreterCode.start + I.interpreterCode.header.intSpcEntryOffset;
	}

	def gen() -> MemoryRange {
		var range = MemoryRange.new(CiRuntime.RESERVED_CODE_START, CiRuntime.RESERVED_CODE_END);
		if (I.interpreterCode != null) return range;
		// Deseralize or generate the pregen stubs
		I.interpreterCode = Metrics.pregen_time_us.run(deserializeOrGenerateCode, range);
		Metrics.pregen_bytes.val += u64.!(I.interpreterCode.end - I.interpreterCode.start);

		if (Debug.pregen) Trace.OUT.put1("Created pregen stubs in %d \xCE\xBCs.\n", Metrics.pregen_time_us.val).ln();
	}
	def genAndWriteIntoExecutable(executable: Array<byte>) -> bool {
		var pregenCode = gen().range();
		var d = DataReader.new(executable);
		var offset = int.!(CiRuntime.RESERVED_CODE_FILE_OFFSET - Pointer.NULL);
		if (Debug.pregen) Trace.OUT.put2("Pregen buffer in executable @+%d (0x%x)", offset, offset).ln();
		for (i < pregenCode.length) executable[offset + i] = pregenCode[i];
		return true;
	}
	def deserializeOrGenerateCode(range: MemoryRange) -> X86_64InterpreterCode {
		Debug.beforePregen();
		ic.start = range.start;

		// Try deserializing the pregen code offsets directly from the global buffer.
		var marker = pregen_header.codeMarker;
		if (Debug.pregen) {
			Trace.OUT.put2("Pregen buffer marker = 0x%x (0x%x indicates generated)",
				marker, PREGEN_CODE_MARKER).ln();
		}
		if (pregen_header.codeMarker == PREGEN_CODE_MARKER) {
			if (Debug.pregen) {
				Trace.OUT.put2("Pregen stubs exist in [0x%x ... 0x%x]",
					(range.start - Pointer.NULL),
					(range.end - Pointer.NULL));
				Trace.OUT.ln();
			}
		} else {
			//         pregen buffer v   [0 ...                                         TOTAL_SIZE  ]
			//      |xxxxxxxxxxxxxxxx|h|l|pregen_header|...|dispatch|...|inline_code|ool_code|___
			//      ^----elem0_offset----^
			// page ^                                1KiB  ^       page ^      page ^
			var mask = 4095L;
			var elem0_offset = (range.start - Pointer.NULL) & mask;
			var alloc_offset = elem0_offset + 8 + pregen_header_size;
			var aligned_offset = (alloc_offset + mask) & ~mask;
			var skip = int.!(aligned_offset - elem0_offset);

			if (Debug.pregen) {
				Trace.OUT.put3("Generating pregen stubs into [0x%x ... 0x%x], skipping %d bytes",
					(range.start - Pointer.NULL),
					(range.end - Pointer.NULL),
					skip);
				Trace.OUT.ln();
			}

			var w = DataWriter.new().reset(range.range(), 0, 0);
			// Gen interpreter
			X86_64InterpreterGen.new(ic, w).gen(range);
			// Gen all stubs.
			for (l = global_stub_list; l != null; l = l.tail) {
				var stub = l.head;
				stub.offsets.start = w.atEnd().pos;
				stub.gen(ic, w);
				stub.offsets.end = w.atEnd().pos;
			}
			ic.header.codeEnd = w.atEnd().pos;
			ic.header.codeMarker = PREGEN_CODE_MARKER;
		}
		// Finish the interpreter code.
		ic.end = range.start + ic.header.codeEnd;
		ic.setV3Entry();
		I.interpreterCode = ic;
		I.dispatchTable = ic.start +
			if(Instrumentation.probes.elem != null,
				ic.header.probedDispatchTableOffset,
				ic.header.fastDispatchTableOffset);

		// Write-protect the executable code for security and debugging
		Mmap.protect(range.start + ic.header.codeStart, u64.!(ic.header.codeEnd - ic.header.codeStart), Mmap.PROT_READ | Mmap.PROT_EXEC);

		// The host call stub is part of interpreter code (TODO: does it need to be?)
		hostCallStub.start = ic.start + ic.header.hostCallStubOffset;
		hostCallStub.end = ic.start + ic.header.hostCallStubEnd;

		// Register user code objects with the Virgil runtime.
		RiRuntime.registerUserCode(ic);

		RiRuntime.registerUserCode(hostCallStub);

		// Register all stubs that have user code with the Virgil runtime.
		for (l = global_stub_list; l != null; l = l.tail) {
			var stub = l.head;
			if (stub.userCode == null) continue;
			stub.userCode.start = range.start + stub.offsets.start;
			stub.userCode.end = range.start + stub.offsets.end;
			RiRuntime.registerUserCode(stub.userCode);
		}

		// Trace results to help in debugging
		if (Debug.pregen || Debug.interpreter || Trace.compiler || Debug.compiler) {
			var s = range.start - Pointer.NULL;
			Trace.OUT
				.puts("Pregen interpreter and compiler stub addresses:\n")
				.put1("\tcode start:                0x%x\n", s + ic.header.codeStart)
				.put1("\thost call stub:     break *0x%x\n", s + ic.header.hostCallStubOffset)
				.put1("\tv3->int entry:      break *0x%x\n", s + ic.header.intV3EntryOffset)
				.put1("\tspc->int entry:     break *0x%x\n", s + ic.header.intSpcEntryOffset)
				.put1("\tint->int entry:     break *0x%x\n", s + ic.header.intIntEntryOffset)
				.put1("\tfast dispatch:             0x%x\n", s + ic.header.fastDispatchTableOffset)
				.put1("\tprobed dispatch:           0x%x\n", s + ic.header.probedDispatchTableOffset)
				.put1("\toob memory:         break *0x%x\n", s + ic.header.oobMemoryHandlerOffset)
				.put1("\tdivide by zero:     break *0x%x\n", s + ic.header.divZeroHandlerOffset)
				.put1("\tstack overflow:     break *0x%x\n", s + ic.header.stackOverflowHandlerOffset)
				.put1("\tcode end:                  0x%x\n", s + ic.header.codeEnd);
			for (l = global_stub_list; l != null; l = l.tail) {
				var stub = l.head;
				Trace.OUT
					.tab().mark().puts(stub.name).putc(':').ljustify_mark(22)
					.put2(" 0x%x - 0x%x\n",	s + stub.offsets.start, s + stub.offsets.end);
			}
			Trace.OUT.ln();
		}
		Debug.afterPregen();
		return ic;
	}
}
